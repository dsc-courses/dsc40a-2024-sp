{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>This notebook contains code (e.g. the answers to exercises) that was written live during Lecture 5. If you haven't already watched and work through this lecture, you might find it more beneficial to look at the \"blank\" version of this lecture and answer the exercises yourself.</b>\n",
    "</div>\n",
    "\n",
    "# Lecture 5 â€“ Exploratory Data Analysis and Data Cleaning\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements ðŸ“£\n",
    "\n",
    "- Project 1 is due on **Saturday, January 27th**.\n",
    "- Lab 3 will be released tonight and will be due on **Monday, January 29th**.\n",
    "- If you submitted Lab 2, make sure to attend discussion tomorrow and submit the reflection form on Gradescope by **this Thursday** for extra credit!\n",
    "    - Plans for discussion tomorrow, in addition to lab review: the difference between `int` and `np.int64`, a review of the various DataFrameGroupBy methods (`agg`, `transform`, `filter`, `apply`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda ðŸ“†\n",
    "\n",
    "- Other data representations.\n",
    "- Dataset overview.\n",
    "- Introduction to `plotly`.\n",
    "- Exploratory data analysis and feature types.\n",
    "- Data cleaning.\n",
    "    - Data quality checks.\n",
    "    - Missing values.\n",
    "    - Transformations and timestamps.\n",
    "    - Modifying structure.\n",
    "- Investigating student-submitted questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa56a0ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://q.dsc80.com\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://q.dsc80.com)! If the link doesn't work for you, click the [**ðŸ¤” Lecture Questions**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform) link in the top right corner of the course website.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b989f24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other data representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f289f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representations of tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5129a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DSC 80, we work with DataFrames in `pandas`.\n",
    "    - When we say `pandas` DataFrame, we're talking about the `pandas` API for its DataFrame objects.\n",
    "        - API stands for \"application programming interface.\" We'll learn about these more soon.\n",
    "    - When we say \"DataFrame\", we're referring to a general way to represent data (rows and columns, with labels for both rows and columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0854bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There many other ways to work with data tables! \n",
    "    - Examples: R data frames, SQL databases, spreadsheets, or even matrices from linear algebra.\n",
    "    - When you learn SQL in DSC 100, you'll find many similaries (e.g. slicing columns, filtering rows, grouping, joining, etc.).\n",
    "    - **Relational algebra** captures common data operations between many data table systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0256850e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why use DataFrames over something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f5cb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrames vs. spreadsheets\n",
    "\n",
    "- DataFrames give us a **data lineage**: the code records down data changes. Not so in spreadsheets!\n",
    "- Using a general-purpose programming language gives us the ability to handle much larger datasets, and we can use distributed computing systems to handle massive datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91460c02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrames vs. matrices\n",
    "\n",
    "\\begin{split}\n",
    "\\begin{aligned}\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 4 \\\\\n",
    "0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "\\end{split}\n",
    "\n",
    "- Matrices are mathematical objects. They only hold numbers, but have many useful properties (which you've learned about in your linear algebra class, Math 18).\n",
    "- Often, we process data from a DataFrame into matrix format for machine learning models. You saw this a bit in DSC 40A, and we'll see this more in DSC 80 in a few weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a834c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrames vs. relations\n",
    "\n",
    "- Relations are the data representation for relational database systems (e.g. MySQL, PostgreSQL, etc.).\n",
    "- You'll learn all about these in DSC 100.\n",
    "- Database systems are much better than DataFrames at storing **many** data tables and handling concurrency (many people reading and writing data at the same time).\n",
    "- Common workflow: load a subset of data in from a database system into `pandas`, then make a plot.\n",
    "- Or: load and clean data in `pandas`, then store it in a database system for others to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed6c3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5d3b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### San Diego food safety\n",
    "\n",
    "From [this article](https://inewsource.org/2023/02/09/san-diego-restaurants-food-safety-violations/) ([archive link](https://archive.ph/gz8BL)):\n",
    "\n",
    "> In the last three years, one third of San Diego County restaurants have had at least one major food safety violation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a6782",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 99% Of San Diego Restaurants Earn â€˜A' Grades, Bringing Usefulness of System Into Question\n",
    "\n",
    "From [this article](https://www.nbcsandiego.com/news/local/99-of-san-diego-restaurants-earn-a-grades-bringing-usefulness-of-system-into-question/25381/) ([archive link](https://archive.ph/yB6RU)):\n",
    "\n",
    "> Food held at unsafe temperatures. Employees not washing their hands. Dirty countertops. Vermin in the kitchen. An expired restaurant permit.\n",
    "> \n",
    "> Restaurant inspectors for San Diego County found these violations during a routine health inspection of a diner in La Mesa in November 2016. Despite the violations, the restaurant was awarded a score of 90 out of 100, the lowest possible score to achieve an â€˜Aâ€™ grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac10042",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data\n",
    "\n",
    "- We downloaded the data about the 1000 restaurants closest to UCSD from [here](https://www.sandiegocounty.gov/content/sdc/deh/fhd/ffis/intro.html.html).\n",
    "- We had to download the data as JSON files, then process it into DataFrames. You'll learn how to do this soon!\n",
    "    - Until now, you've (largely) been presented with CSV files that `pd.read_csv` could load without any issues.\n",
    "    - But there are many different formats and possible issues when loading data in from files.\n",
    "    - See [Chapter 8 of Learning DS](https://learningds.org/ch/08/files_intro.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_path = Path('data') / 'restaurants.csv'\n",
    "insp_path = Path('data') / 'inspections.csv'\n",
    "viol_path = Path('data') / 'violations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = pd.read_csv(rest_path)\n",
    "insp = pd.read_csv(insp_path)\n",
    "viol = pd.read_csv(viol_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57983d32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "    The first article said that one third of restaurants had at least one major safety violation.<br>\n",
    "    Which DataFrames and columns seem most useful to verify this?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8367ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb951ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf62cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b64207",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cbd01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction to `plotly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f270da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `plotly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba464496",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've used `plotly` in lecture briefly, and you even have to use it in Project 1 Question 13, but we haven't yet discussed it formally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d895a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's a visualization library that enables **interactive** visualizations.\n",
    "\n",
    "<center><img src=\"imgs/plotly.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d9f3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `plotly`\n",
    "\n",
    "There are a few ways we can use `plotly`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622401c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using the `plotly.express` syntax.\n",
    "    - `plotly` is very flexible, but it can be verbose; `plotly.express` allows us to make plots quickly.\n",
    "    - See the [**documentation here**](https://plotly.com/python/plotly-express) â€“ it's very rich (there are good examples for almost everything)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d84013",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By setting `pandas` plotting backend to `'plotly'` (by default, it's `'matplotlib'`) and using the DataFrame `plot` method.\n",
    "    - The DataFrame `plot` method is how you created plots in DSC 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd73d31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For now, we'll use `plotly.express` syntax; we've imported it in the `dsc80_utils.py` file that we import at the top of each lecture notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a04b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Initial plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85364a84",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's look at the distribution of inspection `'score'`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(insp['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de6973",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How about the distribution of average inspection `'score'` per `'grade'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = (\n",
    "    insp[['grade', 'score']]\n",
    "    .groupby('grade')\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e201097",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(scores, x='grade', y='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b951fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.plot(kind='bar', x='grade', y='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16546d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploratory data analysis and feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50511216",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data science lifecycle, revisited\n",
    "\n",
    "<center>\n",
    "    <img src=\"imgs/ds-lifecycle.svg\" width=50%>\n",
    "</center>\n",
    "\n",
    "We're at the stage of **understanding the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4dcfca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132e354",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Historically, data analysis was dominated by formal statistics, including tools like confidence intervals, hypothesis tests, and statistical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719dca9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In 1977, John Tukey [defined](https://search.worldcat.org/title/3058187) the term **exploratory data analysis**, which described a philosophy for proceeding about data analysis:\n",
    "\n",
    "> Exploratory data analysis is actively incisive, rather than passively descriptive, with real emphasis on the discovery of the unexpected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8ed6b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Practically, EDA involves, among other things, computing summary statistics and drawing plots to understand the nature of the data at hand.\n",
    "\n",
    "> The greatest gains from data come from surprisesâ€¦ The unexpected is best brought to our attention by **pictures**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41ad00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different feature types\n",
    "\n",
    "<center><img src='imgs/data-types.png' width=90%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7696f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "    Determine the <b>feature type</b> of each of the following variables.\n",
    "    \n",
    "- `insp['score']`\n",
    "- `insp['grade']`\n",
    "- `viol['violation_accela']`\n",
    "- `viol['major_violation']`\n",
    "- `rest['business_id']`\n",
    "- `rest['opened_date']`\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252004ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca685bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol['violation_accela']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8abfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol['major_violation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21cef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest['opened_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32888d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature types vs. data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d134d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The data type `pandas` uses is not the same as the \"data type\" we talked about just now!\n",
    "    - There's a difference between feature type and computational data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e8b34",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Take care when the two don't match up very well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dab3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas stores these as ints, but they're actually nominal.\n",
    "rest['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas stores these as strings, but they're actually numeric.\n",
    "rest['opened_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdcc40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e1505",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Four pillars of data cleaning\n",
    "\n",
    "When loading in a dataset, to clean the data â€“ that is, to prepare it for further analysis â€“ we will:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541c705",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Perform **data quality checks**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c78dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Identify and handle **missing values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea07074",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Perform **transformations**, including converting time series data to **timestamps**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6965ad8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Modify **structure** as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8786b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92564b1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data quality checks\n",
    "\n",
    "We often start an analysis by checking the quality of the data.\n",
    "\n",
    "- Scope: Do the data match your understanding of the population? \n",
    "- Measurements and values: Are the values reasonable?\n",
    "- Relationships: Are related features in agreement?\n",
    "- Analysis: Which features might be useful in a future analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdeb3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scope\n",
    "\n",
    "Do the data match your understanding of the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ecab4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We were told that we're only looking at the 1000 restaurants closest to UCSD, so the restaurants in `rest` should agree with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef21b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df0230",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measurements and values\n",
    "\n",
    "Are the values reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c5d81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do the values in the `'grade'` column match what we'd expect grades to look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce83dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72806b8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What kinds of information does the `insp` DataFrame hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3206cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f33640",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What's going on in the `'address'` column of `rest`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there multiple restaurants with the same address?\n",
    "rest['address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps all rows with duplicate addresses.\n",
    "(\n",
    "    rest\n",
    "    .groupby('address')\n",
    "    .filter(lambda df: df.shape[0] >= 2)\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ace0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the same thing as above!\n",
    "rest[rest.duplicated(subset=['address'], keep=False)].sort_values('address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773936b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relationships\n",
    "\n",
    "Are related features in agreement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4836c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do the `'address'`es and `'zip'` codes in `rest` match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4895b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest[['address', 'zip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8838b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What about the `'score'`s and `'grade'`s in `insp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7a3c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analysis\n",
    "\n",
    "Which features might be useful in a future analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80378d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We're most interested in:\n",
    "    - These columns in the `rest` DataFrame: `'business_id'`, `'name'`, `'address'`, `'zip'`, and `'opened_date'`.\n",
    "    - These columns in the `insp` DataFrame: `'business_id'`, `'inspection_id'`, `'score'`, `'grade'`, `'completed_date'`, and `'status'`.\n",
    "    - These columns in the `viol` DataFrame: `'inspection_id'`, `'violation'`, `'major_violation'`, `'violation_text'`, and `'violation_accela'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a10c70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Also, let's rename a few columns to make them easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26694343",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ðŸ’¡ Pro-Tip: Using `pipe`\n",
    "\n",
    "When we manipulate DataFrames, it's best to define individual functions for each step, then use the `pipe` **method** to chain them all together.\n",
    "\n",
    "The `pipe` DataFrame method takes in a function, which itself takes in a DataFrame and returns a DataFrame.\n",
    "\n",
    "- In practice, we would add functions one by one to the top of a notebook, then `pipe` them all.\n",
    "- For today, will keep re-running `pipe` to show data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_rest(rest):\n",
    "    return rest[['business_id', 'name', 'address', 'zip', 'opened_date']]\n",
    "\n",
    "rest = (\n",
    "    pd.read_csv(rest_path)\n",
    "    .pipe(subset_rest)\n",
    ")\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2580209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above â€“ but the above makes it easier to chain more .pipe calls afterwards.\n",
    "subset_rest(pd.read_csv(rest_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e751e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use `pipe` to keep (and rename) the subset of the columns we care about in the other two DataFrames as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_insp(insp):\n",
    "    return (\n",
    "        insp[['business_id', 'inspection_id', 'score', 'grade', 'completed_date', 'status']]\n",
    "        .rename(columns={'completed_date': 'date'})\n",
    "    )\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_viol(viol):\n",
    "    return (\n",
    "        viol[['inspection_id', 'violation', 'major_violation', 'violation_accela']]\n",
    "        .rename(columns={'violation': 'kind',\n",
    "                         'major_violation': 'is_major',\n",
    "                         'violation_accela': 'violation'})\n",
    "    )\n",
    "\n",
    "viol = (\n",
    "    pd.read_csv(viol_path)\n",
    "    .pipe(subset_viol)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fd7f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining the restaurant data\n",
    "\n",
    "Let's join all three DataFrames together so that we have all the data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88827b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeadb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ca1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_restaurant_data():\n",
    "    return (\n",
    "        rest\n",
    "        .merge(insp, on='business_id', how='left')\n",
    "        .merge(viol, on='inspection_id', how='left')\n",
    "    )\n",
    "\n",
    "df = merge_all_restaurant_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92823e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007e6ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing values\n",
    "\n",
    "Next, it's important to check for and handle missing values, as they can have a big effect on your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8190fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proportion of values in each column that are missing.\n",
    "insp.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdee4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Why are there null values here?\n",
    "# insp['inspection_id'] and viol['inspection_id'] don't have any null values...\n",
    "df['inspection_id'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afddb353",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are many ways of handling missing values, which we'll cover in an entire lecture next week. But a good first step is to check how many there are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f39cbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Transformations and timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce00205",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformations and timestamps\n",
    "\n",
    "From last class:\n",
    "\n",
    "> A transformation results from performing some operation on every element in a sequence, e.g. a Series.\n",
    "\n",
    "It's often useful to look at ways of transforming your data to make it easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49aa31e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Type conversions (e.g. changing the string `\"$2.99\"` to the number `2.99`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bb937",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Unit conversion (e.g. feet to meters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473ffa7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Extraction (Getting `'vermin'` out of `'Vermin Violation Recorded on 10/10/2023'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87244b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating timestamps\n",
    "\n",
    "Most commonly, we'll parse dates into `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype!\n",
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adaa896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This magical string tells Python what format the date is in.\n",
    "# For more info: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "date_format = '%Y-%m-%d'\n",
    "pd.to_datetime(insp['date'], format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dee4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Another advantage of defining functions is that we can reuse this function\n",
    "# for the 'opened_date' column in `rest` if we wanted to.\n",
    "def parse_dates(insp, col):\n",
    "    date_format = '%Y-%m-%d'\n",
    "    dates = pd.to_datetime(insp[col], format=date_format)\n",
    "    return insp.assign(**{col: dates})\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    "    .pipe(parse_dates, 'date')\n",
    ")\n",
    "\n",
    "# We should also remake df, since it depends on insp.\n",
    "# Note that the new insp is used to create df!\n",
    "df = merge_all_restaurant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype now!\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9739b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with timestamps\n",
    "\n",
    "- We often want to adjust granularity of timestamps to see overall trends, or seasonality.\n",
    "- Use the `resample` method in `pandas` ([documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)).\n",
    "    - Think of it like a version of `groupby`, but for timestamps.\n",
    "    - For instance, `insp.resample('2W', on='date')` separates every two weeks of data into a different group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.resample('2W', on='date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are those numbers coming from?\n",
    "insp[(insp['date'] >= pd.Timestamp('2020-01-05')) &\n",
    "     (insp['date'] < pd.Timestamp('2020-01-19'))]['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d55148",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.resample('2W', on='date')['score'].mean().plot(title='Average Violation Over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622796b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.dt` accessor\n",
    "\n",
    "Like with Series of strings, `pandas` has a `.dt` accessor for properties of timestamps ([documentation](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14818dc0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "insp['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71848903",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "insp['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ae178",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    insp['date'].dt.dayofweek.value_counts()\n",
    ")\n",
    "fig.update_xaxes(tickvals=np.arange(7), ticktext=['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206c9b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Modifying structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ddb97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reshaping DataFrames\n",
    "\n",
    "We often **reshape** the DataFrame's structure to make it more convenient for analysis. For example, we can:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044dd171",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Simplify structure by removing columns or taking a set of rows for a particular period of time or geographic area.\n",
    "    - We already did this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8267529",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Adjust granularity by aggregating rows together.\n",
    "    - To do this, use `groupby` (or `resample`, if working with timestamps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcea8a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Reshape structure, most commonly by using the DataFrame `melt` method to un-pivot a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e99cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `melt`\n",
    "\n",
    "- The `melt` method is common enough that we'll give it a special mention.\n",
    "- We'll often encounter pivot tables (esp. from government data), which we call *wide* data.\n",
    "- The methods we've introduced work better with *long-form* data, or *tidy* data.\n",
    "- To go from wide to long, `melt`.\n",
    "\n",
    "<center><img src='imgs/wide-vs-long.svg' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e43c42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example usage of `melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example = pd.DataFrame({\n",
    "    'Year': [2001, 2002],\n",
    "    'Jan': [10, 130],\n",
    "    'Feb': [20, 200],\n",
    "    'Mar': [30, 340]\n",
    "}).set_index('Year')\n",
    "wide_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc75510",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example.melt(ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77837e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67478028",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://q.dsc80.com\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "What questions do you want me to try and answer with the data? I'll start with a single pre-prepared question, and then answer student questions until we run out of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b53b97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example question: Can we rank restaurants by their number of violations? How about separately for each zip code?\n",
    "\n",
    "And why would we want to do that? ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_violations = lambda df: (\n",
    "    df\n",
    "    .groupby('name')\n",
    "    ['zip']\n",
    "    .agg(['first', 'size'])\n",
    "    .sort_values('size', ascending=False)\n",
    "    .reset_index()\n",
    "    .pipe(lambda frame: frame.assign(rank=frame.index + 1).rename(columns={'first': 'zip'}))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pipe(rank_by_violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby('zip')\n",
    "    .apply(rank_by_violations)\n",
    "    .reset_index(drop=True)\n",
    "    .pivot(index='rank', columns='zip', values='name')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e163f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('zip == \"92014-3149\"').value_counts('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b164bd4",
   "metadata": {},
   "source": [
    "### Example question: Which restaurants have vermin violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df[df['violation'].str.lower().str.contains('vermin', na=False)]\n",
    "    .value_counts('name')\n",
    "    .head(6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a19c5",
   "metadata": {},
   "source": [
    "### Example question: What are some of the most uncommon violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ac54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('kind').filter(lambda df: df.shape[0] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3ae8a",
   "metadata": {},
   "source": [
    "### What's the worst subway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'].str.lower().str.contains('subway')].value_counts('address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d5d0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd620d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Data cleaning is a necessary starting step in data analysis. There are four pillars of data cleaning:\n",
    "    - Quality checks.\n",
    "    - Missing values.\n",
    "    - Transformations and timestamps.\n",
    "    - Modifying structure.\n",
    "- Approach EDA with an open mind, and draw lots of visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8419fc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Hypothesis and permutation testing. Some of this will be DSC 10 review, but we'll also push further! **Expect a pre-lecture reading tomorrow!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
